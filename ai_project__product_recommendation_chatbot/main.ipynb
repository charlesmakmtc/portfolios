{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be8d969",
   "metadata": {},
   "source": [
    "### **Introduction to the Smartwatch Product Recommendation Chatbot**\n",
    "\n",
    "This code implements a **smartwatch product recommendation chatbot** powered by \n",
    "- **large language model (LLM)**, \n",
    "- **Singe Agent with Prompt (via Langchain)**, and \n",
    "- **Retrieval-Augmented Generation (RAG)** techniques. \n",
    "\n",
    "The system is designed to \n",
    "recommend smartwatches based on user preferences and product features, while ensuring the response \n",
    "appears natural and not explicitly tied to the provided context.\n",
    "\n",
    "### Key Components and Workflow:\n",
    "1. **LLM Integration**:  \n",
    "   The chatbot uses the **Qwen3:14B** model via the `langchain_ollama` library, which is hosted on a \n",
    "local LLM server. This model is responsible for understanding user queries, retrieving relevant \n",
    "product information, and generating tailored recommendations.\n",
    "\n",
    "2. **Product Catalog**:  \n",
    "   A static product catalog is embedded in the code, containing details about two smartwatches:  \n",
    "   - **Military-grade \"ABC123\"**: Waterproof (IP68), long battery life (20+ days), heavy (300g).  \n",
    "   - **Leisure-grade \"DEF456\"**: Lightweight (50g), non-waterproof, medium battery life (~50 hours).  \n",
    "\n",
    "\n",
    "3. **RAG Pipeline**:  \n",
    "   - The product catalog is converted into a **vector store** using `InMemoryVectorStore`, enabling \n",
    "efficient semantic search.  \n",
    "   - When a user asks a question (e.g., \"Recommend a product for underwater outdoor activities\"), the \n",
    "system retrieves the most relevant product details from the vector store.  \n",
    "\n",
    "4. **Prompt Engineering**:  \n",
    "   - A **system prompt** guides the LLM to answer questions based on the retrieved context without \n",
    "explicitly mentioning the source.  \n",
    "   - A **chain** is constructed using `ChatPromptTemplate`, combining the retrieved product data, \n",
    "user question, and instructions for the LLM.  \n",
    "\n",
    "5. **Output**:  \n",
    "   The final recommendation is generated by the LLM and returned as a natural language response. For \n",
    "example, if a user asks for a waterproof smartwatch for underwater activities, the system would \n",
    "prioritize recommending the **military-grade \"ABC123\"** model.  \n",
    "\n",
    "### Example Use Case:  \n",
    "If a user says:  \n",
    "> \"Recommend me a product for me. I am a businessman and love outdoor activities under water.\"  \n",
    "\n",
    "The chatbot will:  \n",
    "1. Retrieve the waterproof \"ABC123\" product details from the vector store.  \n",
    "2. Generate a recommendation highlighting its IP68 rating and long battery life, tailored to the \n",
    "user’s needs.  \n",
    "\n",
    "This approach ensures the chatbot provides accurate, context-aware recommendations while maintaining \n",
    "a seamless user experience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083747f6",
   "metadata": {},
   "source": [
    "## Code impelementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b457f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama.llms import Client\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb3406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   setup LLM server\n",
    "llm_server_url    = os.getenv('LLM_SERVER_URL')\n",
    "llm_model_name    = \"qwen3:14b\"\n",
    "client = Client(llm_server_url)\n",
    "llm = ChatOllama(_client=client, model=llm_model_name)\n",
    "embeddings = OllamaEmbeddings(model=llm_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "213fbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   smartwatch product catalog \n",
    "context = \"\"\"\n",
    "Below are our smart watch products, including product features and introduction::\n",
    "    - Product Code: \"ABC123\"\n",
    "        - product grade: military\n",
    "        - product features: \n",
    "            - waterproof (IP68)\n",
    "            - long battery life (support over 20 days)\n",
    "            - weight is heavy (300g)\n",
    "            \n",
    "    - Product Code: \"DEF456\n",
    "        - product grade: leisure\n",
    "        - product features: \n",
    "            - weight is light (50g)\n",
    "            - non-waterproof\n",
    "            - medium battery life (~ 50 hours)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32207a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   RAG (convert smartwatch product catalog to vectorstore)\n",
    "vectorstore = InMemoryVectorStore.from_texts([context], embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dd053e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   write single agent & prompt\n",
    "system_message = \"\"\"\n",
    "Answer the following question based on this context but Do not mention the information is provided by context:\n",
    "Question: {human_question}\n",
    "\n",
    "Based on the above context:\n",
    "When you recommend a product based on the `product_catalog_context`, you must think step by step.\n",
    "\"\"\"\n",
    "\n",
    "product_catalog = \"\"\"\n",
    "    Below are product catalog: \n",
    "        <product_catalog_context>\n",
    "        {product_catalog_context}\n",
    "        </product_catalog_context>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bef47e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   setup chain\n",
    "chain = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message),\n",
    "    (\"system\", product_catalog),\n",
    "    (\"human\", \"{human_question}\")\n",
    "])\n",
    "\n",
    "Product_Recommendation_QA_chain = (\n",
    "        {\n",
    "            \"product_catalog_context\": retriever,\n",
    "            \"human_question\": RunnablePassthrough(),\n",
    "        } | chain | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c9fc1",
   "metadata": {},
   "source": [
    "### chatbot service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebed058c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is a businessman who loves underwater outdoor activities. Let me check the product catalog.\n",
      "\n",
      "First, there are two smartwatches: ABC123 and DEF456. \n",
      "\n",
      "For ABC123: It's military-grade, waterproof (IP68), battery lasts over 20 days, but it's heavy (300g). Since the user does underwater activities, waterproof is essential. The long battery life is good for outdoor trips. However, the weight might be a downside if he prefers lightweight gear.\n",
      "\n",
      "DEF456 is leisure-grade, not waterproof, light (50g), but battery only lasts 50 hours. Since the user needs waterproofing for underwater activities, DEF456 isn't suitable. \n",
      "\n",
      "So, only ABC123 meets the waterproof requirement. Even though it's heavy, the other features might be worth it. I should recommend ABC123 and mention the trade-offs.\n",
      "</think>\n",
      "\n",
      "Based on your needs as a businessman who enjoys underwater outdoor activities, here’s a tailored recommendation:\n",
      "\n",
      "### **Recommended Product:**\n",
      "**Product Code: \"ABC123\"**  \n",
      "- **Grade:** Military  \n",
      "- **Key Features:**  \n",
      "  - **Waterproof (IP68):** Ideal for underwater activities (e.g., swimming, diving).  \n",
      "  - **Long Battery Life:** Lasts over 20 days, reducing the need for frequent charging during extended outdoor trips.  \n",
      "  - **Durability:** Military-grade build ensures reliability in harsh environments.  \n",
      "- **Drawback:** Heavier weight (300g) compared to lighter alternatives.  \n",
      "\n",
      "### **Other Options (Not Suitable for Underwater Use):**  \n",
      "**Product Code: \"DEF456\"**  \n",
      "- **Grade:** Leisure  \n",
      "- **Key Features:**  \n",
      "  - **Lightweight (50g):** Comfortable for daily wear.  \n",
      "  - **Medium Battery Life:** ~50 hours.  \n",
      "- **Drawback:** **Non-waterproof** – Not suitable for underwater activities.  \n",
      "\n",
      "### **Final Note:**  \n",
      "If underwater durability is a priority, **ABC123** is the only viable option. Its weight may be a trade-off for robustness and waterproofing. For non-waterproof scenarios, DEF456 could be considered for its lightweight design.\n"
     ]
    }
   ],
   "source": [
    "#   chatbot session start\n",
    "human_question = \"Recommend me a product for me. I am a business man, and love outdoor activities under water. List out all for me\"\n",
    "ai_product_recommendation = Product_Recommendation_QA_chain.invoke(input=human_question)\n",
    "print(ai_product_recommendation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
